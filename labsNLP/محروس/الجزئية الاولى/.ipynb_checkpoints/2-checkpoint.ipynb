{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetCriteria = got.manager.TweetCriteria().setNear(\"Saudi Arabia\")\\\n",
    "#                                            .setSince(\"2019-11-19\")\\\n",
    "#                                            .setUntil(\"2019-11-21\")\\\n",
    "#                                            .setMaxTweets(1000)\n",
    "\n",
    "# tweet = got.manager.TweetManager.getTweets(tweetCriteria)[0:1000]\n",
    "# text=tweet\n",
    "# f= open(\"res1.txt\",\"w+\", encoding=\"utf-8\")\n",
    "# for i in text:\n",
    "#     f.write(f'{i.text}\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLinks(text):\n",
    "    LINK_RS = r'http(s)?\\S+'\n",
    "    PIC_LINK_RS = r'pic\\S+'\n",
    "    result = re.sub(LINK_RS,' ', text)\n",
    "    result = re.sub(PIC_LINK_RS,' ', result)\n",
    "\n",
    "    return(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def normalizeLetters(text):\n",
    "    #لاازالة الحروف المتتكرة في مشكلة انو اذا كانو حربين ولا بعض نفس الشي بيساويهون واحد مثلا https ->htps\n",
    "    REMOVE_REPETITION = r'(.)\\1+'\n",
    "    \n",
    "    result = re.sub(REMOVE_REPETITION, r'\\1', text)\n",
    "    #تصليح ههه\n",
    "    #في مشكلة لما تكون هههه باخر الجملة\n",
    "    result = re.sub(' ه(\\s|$)',\" ههه \" ,result)\n",
    "    result = re.sub(\"[أآ]\", \"ا\", result)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"text.txt\",\"r\")\n",
    "text2 = open(\"output.txt\",\"w\", encoding=\"utf-8\")\n",
    "lines = text.readlines()\n",
    "for line in lines:\n",
    " \n",
    "    newLine = removeLinks(line)\n",
    "\n",
    "    newLine = normalizeLetters(newLine)\n",
    " \n",
    "\n",
    "    \n",
    "    text2.write(newLine)\n",
    "text2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hashtags(text): \n",
    "    text=re.findall(r\"#[\\w\\d_]+\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#تخزيت الداتا من النص لمتحول data\n",
    "f= open(\"output.txt\",\"r\", encoding=\"utf-8\")\n",
    "data=f.readlines()\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#ايران_برا_بلاد_العرب_حره', 5), ('#Aple', 4), ('#فيصل_سبعين_محب', 3), ('#iPhone', 3), ('#الضمان', 3), ('#الكويت', 3), ('#تجمع_العاطلين_السعودين42', 2), ('#الجبهة_الشعبية_لتحرير_راديو', 2), ('#كلنا_الميسري_الجبواني', 2), ('#لاتغرد_في_هشتاق_سيء_ولو_نصيحه', 2)]\n"
     ]
    }
   ],
   "source": [
    "#استخدمنا ملف جديد لتخزين الداتا النظيفة \n",
    "#مررنا هذه الداتا لتابع الهاشتاغ لايجاد الهاشتاغات وخزناها في مصفوفة ثم ماوجدنا اكثر الهاشتاغات المكررة باستخدام تابع most_common()\n",
    "hashs=[]\n",
    "for line in data:    \n",
    " \n",
    "    if len(hashtags(line))!=0:\n",
    "        hashs.append(hashtags(line))\n",
    "\n",
    "\n",
    "hashs = [ h for array in hashs for h in array]\n",
    "fdist = nltk.FreqDist(hashs)\n",
    "top = fdist.most_common(10)\n",
    "print(top)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAnalysis(text,n):\n",
    "    words =[ nltk.word_tokenize(t) for t in text]\n",
    "    n_gram = [list(nltk.ngrams(sent,n)) for sent in words ]\n",
    "    array = [ i for sent_gram in n_gram for i in sent_gram]\n",
    "    fdist = nltk.FreqDist(array)\n",
    "    return fdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('من',), 154), (('.',), 148), (('في',), 94), (('على',), 69), (('اله',), 67), (('ما',), 60), (('#',), 59), (('لا',), 55), (('،',), 55), (('الي',), 50)]\n",
      "\n",
      "[(('شاء', 'اله'), 8), (('.', '.'), 7), (('صباح', 'الخير'), 6), (('الف', 'مبروك'), 6), (('قال', 'الاسد'), 5), (('#', 'ايران_برا_بلاد_العرب_حره'), 5), (('يا', 'كابتن'), 5), ((':', '``'), 4), (('من', 'خلال'), 4), (('.', '#'), 4)]\n",
      "\n",
      "[(('ان', 'شاء', 'اله'), 3), (('وبعد', 'ذالك', 'إلى'), 3), (('مشكلة', 'السعودية', 'مع'), 3), (('حسبي', 'اله', 'ونعم'), 2), (('اله', 'ونعم', 'الوكيل'), 2), (('من', 'خلال', 'شواهد'), 2), (('خلال', 'شواهد', 'واقوال'), 2), (('هذا', 'لانه', 'شان'), 2), (('@', 'zr_zr', '#'), 2), (('zr_zr', '#', 'الجبهة_الشعبية_لتحرير_راديو'), 2)]\n",
      "\n",
      "[(('حسبي', 'اله', 'ونعم', 'الوكيل'), 2), (('من', 'خلال', 'شواهد', 'واقوال'), 2), (('@', 'zr_zr', '#', 'الجبهة_الشعبية_لتحرير_راديو'), 2), (('الشيخ', 'عادل', 'الكلباني', 'الذي'), 2), (('الميسري', 'والجبواني', 'هم', 'الشريان'), 2), (('والجبواني', 'هم', 'الشريان', 'الكبير'), 2), (('هم', 'الشريان', 'الكبير', 'لشرعيه'), 2), (('الشريان', 'الكبير', 'لشرعيه', 'ولن'), 2), (('الكبير', 'لشرعيه', 'ولن', 'نتخلي'), 2), (('لشرعيه', 'ولن', 'نتخلي', 'عنهم'), 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_1=textAnalysis(data,1).most_common(10)\n",
    "\n",
    "top_2=textAnalysis(data,2).most_common(10)\n",
    "top_3=textAnalysis(data,3).most_common(10)\n",
    "top_4=textAnalysis(data,4).most_common(10)\n",
    "# stop word\n",
    "print(top_1,end=\"\\n\\n\")\n",
    "\n",
    "print(top_2,end=\"\\n\\n\")\n",
    "\n",
    "print(top_3,end=\"\\n\\n\")\n",
    "\n",
    "print(top_4,end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
