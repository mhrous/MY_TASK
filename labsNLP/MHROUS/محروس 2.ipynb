{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetCriteria = got.manager.TweetCriteria().setNear(\"Saudi Arabia\")\\\n",
    "#                                            .setSince(\"2019-11-19\")\\\n",
    "#                                            .setUntil(\"2019-11-21\")\\\n",
    "#                                            .setMaxTweets(1000)\n",
    "\n",
    "# tweet = got.manager.TweetManager.getTweets(tweetCriteria)[0:1000]\n",
    "# text=tweet\n",
    "# f= open(\"res1.txt\",\"w+\", encoding=\"utf-8\")\n",
    "# for i in text:\n",
    "#     f.write(f'{i.text}\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLinks(text):\n",
    "    LINK_RS = r'http(s)?\\S+'\n",
    "    PIC_LINK_RS = r'pic\\S+'\n",
    "    result = re.sub(LINK_RS,' ', text)\n",
    "    result = re.sub(PIC_LINK_RS,' ', result)\n",
    "\n",
    "    return(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def normalizeLetters(text):\n",
    "    #لاازالة الحروف المتتكرة في مشكلة انو اذا كانو حربين ولا بعض نفس الشي بيساويهون واحد مثلا https ->htps\n",
    "    REMOVE_REPETITION = r'(.)\\1+'\n",
    "    \n",
    "    result = re.sub(REMOVE_REPETITION, r'\\1', text)\n",
    "    #تصليح ههه\n",
    "    #في مشكلة لما تكون هههه باخر الجملة\n",
    "    result = re.sub(' ه(\\s|$)',\" ههه \" ,result)\n",
    "    result = re.sub(\"[أآ]\", \"ا\", result)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"text.txt\",\"r\")\n",
    "text2 = open(\"output.txt\",\"w\", encoding=\"utf-8\")\n",
    "lines = text.readlines()\n",
    "for line in lines:\n",
    " \n",
    "    newLine = removeLinks(line)\n",
    "\n",
    "    newLine = normalizeLetters(newLine)\n",
    " \n",
    "\n",
    "    \n",
    "    text2.write(newLine)\n",
    "text2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hashtags(text): \n",
    "    text=re.findall(r\"#[\\w\\d_]+\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"output.txt\",\"r\", encoding=\"utf-8\")\n",
    "data=f.readlines()\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top\n",
      "[('#ايران_برا_بلاد_العرب_حره', 5), ('#Aple', 4), ('#فيصل_سبعين_محب', 3)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hashs=[ hashtags(line)  for line in data if len(hashtags(line)) !=0]\n",
    "\n",
    "\n",
    "hashs = [ h for array in hashs for h in array]\n",
    "fdist = nltk.FreqDist(hashs)\n",
    "top = fdist.most_common(3)\n",
    "print(\"top\")\n",
    "print(top)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remov_stopwords(data):\n",
    "    words =[ nltk.word_tokenize(t) for t in data ]\n",
    "    array  =[]\n",
    "    for s in words:\n",
    "        s_wihout_stopwords =([w for w in s if w not in nltk.corpus.stopwords.words('arabic')])\n",
    "        array.append(s_wihout_stopwords)\n",
    "    return array\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAnalysis(text,n):\n",
    "    words =remov_stopwords(data)\n",
    "    n_gram = [list(nltk.ngrams(sent,n)) for sent in words ]\n",
    "    array = [ i for sent_gram in n_gram for i in sent_gram]\n",
    "    fdist = nltk.FreqDist(array)\n",
    "    return fdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gram\n",
      "\n",
      "top\n",
      "[(('.',), 148), (('اله',), 67), (('#',), 59), (('،',), 55), (('الي',), 50), (('و',), 48), (('!',), 45), (('…',), 41), ((':',), 39), (('واله',), 38)]\n",
      "low\n",
      "[('ماينفع',), ('الميزات',), ('عيوب',), ('تجين',), ('شكلج',), ('تسرقين',), ('الخلطه',), ('المقلا',), ('المصديه',), ('فرق',)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2 gram\n",
      "\n",
      "top\n",
      "[(('شاء', 'اله'), 8), (('.', '.'), 7), (('صباح', 'الخير'), 6), (('الف', 'مبروك'), 6), (('قال', 'الاسد'), 5), (('#', 'ايران_برا_بلاد_العرب_حره'), 5), ((':', '``'), 4), (('.', '#'), 4), (('قال', ':'), 4), (('قال', 'الفهد'), 4)]\n",
      "low\n",
      "[('ماينفع', 'تكون'), ('تكون', 'فيكم'), ('فيكم', 'الميزات'), ('الميزات', 'لازم'), ('لازم', 'عيوب'), ('تجين', 'شكلج'), ('شكلج', 'تبين'), ('تبين', 'تسرقين'), ('تسرقين', 'الخلطه'), ('الخلطه', 'او')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3 gram\n",
      "\n",
      "top\n",
      "[(('ان', 'شاء', 'اله'), 3), (('حسبي', 'اله', 'ونعم'), 2), (('اله', 'ونعم', 'الوكيل'), 2), (('خلال', 'شواهد', 'واقوال'), 2), (('@', 'zr_zr', '#'), 2), (('zr_zr', '#', 'الجبهة_الشعبية_لتحرير_راديو'), 2), (('الشيخ', 'عادل', 'الكلباني'), 2), (('الميسري', 'والجبواني', 'الشريان'), 2), (('والجبواني', 'الشريان', 'الكبير'), 2), (('الشريان', 'الكبير', 'لشرعيه'), 2)]\n",
      "low\n",
      "[('ماينفع', 'تكون', 'فيكم'), ('تكون', 'فيكم', 'الميزات'), ('فيكم', 'الميزات', 'لازم'), ('الميزات', 'لازم', 'عيوب'), ('تجين', 'شكلج', 'تبين'), ('شكلج', 'تبين', 'تسرقين'), ('تبين', 'تسرقين', 'الخلطه'), ('تسرقين', 'الخلطه', 'او'), ('الخلطه', 'او', 'المقلا'), ('او', 'المقلا', 'المصديه')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4 gram\n",
      "\n",
      "top\n",
      "[(('حسبي', 'اله', 'ونعم', 'الوكيل'), 2), (('@', 'zr_zr', '#', 'الجبهة_الشعبية_لتحرير_راديو'), 2), (('الميسري', 'والجبواني', 'الشريان', 'الكبير'), 2), (('والجبواني', 'الشريان', 'الكبير', 'لشرعيه'), 2), (('الشريان', 'الكبير', 'لشرعيه', 'ولن'), 2), (('الكبير', 'لشرعيه', 'ولن', 'نتخلي'), 2), (('لشرعيه', 'ولن', 'نتخلي', 'عنهم'), 2), (('ولن', 'نتخلي', 'عنهم', 'ابدا'), 2), (('نتخلي', 'عنهم', 'ابدا', 'سنقف'), 2), (('عنهم', 'ابدا', 'سنقف', 'الوطنين'), 2)]\n",
      "low\n",
      "[('ماينفع', 'تكون', 'فيكم', 'الميزات'), ('تكون', 'فيكم', 'الميزات', 'لازم'), ('فيكم', 'الميزات', 'لازم', 'عيوب'), ('تجين', 'شكلج', 'تبين', 'تسرقين'), ('شكلج', 'تبين', 'تسرقين', 'الخلطه'), ('تبين', 'تسرقين', 'الخلطه', 'او'), ('تسرقين', 'الخلطه', 'او', 'المقلا'), ('الخلطه', 'او', 'المقلا', 'المصديه'), ('او', 'المقلا', 'المصديه', 'فرق'), ('المقلا', 'المصديه', 'فرق', 'رقيج')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5 gram\n",
      "\n",
      "top\n",
      "[(('الميسري', 'والجبواني', 'الشريان', 'الكبير', 'لشرعيه'), 2), (('والجبواني', 'الشريان', 'الكبير', 'لشرعيه', 'ولن'), 2), (('الشريان', 'الكبير', 'لشرعيه', 'ولن', 'نتخلي'), 2), (('الكبير', 'لشرعيه', 'ولن', 'نتخلي', 'عنهم'), 2), (('لشرعيه', 'ولن', 'نتخلي', 'عنهم', 'ابدا'), 2), (('ولن', 'نتخلي', 'عنهم', 'ابدا', 'سنقف'), 2), (('نتخلي', 'عنهم', 'ابدا', 'سنقف', 'الوطنين'), 2), (('عنهم', 'ابدا', 'سنقف', 'الوطنين', '#'), 2), (('ابدا', 'سنقف', 'الوطنين', '#', 'كلنا_الميسري_الجبواني'), 2), (('مقاس', '16', 'بوصة', '#', 'Aple'), 2)]\n",
      "low\n",
      "[('ماينفع', 'تكون', 'فيكم', 'الميزات', 'لازم'), ('تكون', 'فيكم', 'الميزات', 'لازم', 'عيوب'), ('تجين', 'شكلج', 'تبين', 'تسرقين', 'الخلطه'), ('شكلج', 'تبين', 'تسرقين', 'الخلطه', 'او'), ('تبين', 'تسرقين', 'الخلطه', 'او', 'المقلا'), ('تسرقين', 'الخلطه', 'او', 'المقلا', 'المصديه'), ('الخلطه', 'او', 'المقلا', 'المصديه', 'فرق'), ('او', 'المقلا', 'المصديه', 'فرق', 'رقيج'), ('المقلا', 'المصديه', 'فرق', 'رقيج', 'وفولي'), ('المصديه', 'فرق', 'رقيج', 'وفولي', 'هعهعهع')]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(1,6):\n",
    "    print(f\"{_} gram\",end=\"\\n\\n\")\n",
    "    N_Gram=textAnalysis(data,_)\n",
    "    top_1 = N_Gram.most_common(10)\n",
    "    low_1 = N_Gram.hapaxes()[:10]\n",
    "\n",
    "    print(\"top\")\n",
    "    print(top_1)\n",
    "    print(\"low\")\n",
    "    print(low_1)\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
